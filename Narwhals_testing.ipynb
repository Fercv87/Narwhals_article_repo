{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dfed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install narwhals pandas polars pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d18d9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import narwhals as nw\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0857cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000000, 2) (20000, 2)\n",
      "      id   value\n",
      "0   1785   54.31\n",
      "1  15479  123.47\n",
      "2  13091  -15.55 \n",
      "       id region\n",
      "0   1785  North\n",
      "1  15479   West\n",
      "2  13091  North\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000000 entries, 0 to 199999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   id      int64  \n",
      " 1   value   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 3.0 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic dataset using pandas (as a native DataFrame)\n",
    "num_rows = 200_000_000  # 200M rows for demonstration\n",
    "rng = np.random.default_rng(seed=42)\n",
    "pdf_sales = pd.DataFrame({\n",
    "    \"id\": rng.integers(0, 20_000, size=num_rows),        # many repeat IDs to allow groupby\n",
    "    \"value\": rng.normal(loc=100.0, scale=50.0, size=num_rows).round(2),  # some numeric value\n",
    "})\n",
    "# Create a region mapping: each id gets a region label (e.g., \"North\",\"South\",\"East\",\"West\")\n",
    "unique_ids = pdf_sales[\"id\"].unique()\n",
    "regions = [\"North\", \"South\", \"East\", \"West\"]\n",
    "id_to_region = {id_val: rng.choice(regions) for id_val in unique_ids}\n",
    "pdf_regions = pd.DataFrame({\n",
    "    \"id\": list(id_to_region.keys()),\n",
    "    \"region\": [id_to_region[i] for i in id_to_region.keys()]\n",
    "})\n",
    "# Quick peek at data shape\n",
    "print(pdf_sales.shape, pdf_regions.shape)\n",
    "print(pdf_sales.head(3), \"\\n\", pdf_regions.head(3))\n",
    "print(pdf_sales.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f897e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20000 non-null  int64 \n",
      " 1   region  20000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pdf_regions.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52adf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Polars DataFrames for demonstration\n",
    "pl_sales = pl.DataFrame(pdf_sales)\n",
    "pl_regions = pl.DataFrame(pdf_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74bceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the pandas dataframes with Narwhals\n",
    "df_sales_nw = nw.from_native(pdf_sales)\n",
    "df_regions_nw = nw.from_native(pdf_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "itnv2enxx7s",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # For a comprehensive overview similar to pandas .info()\n",
    "def polars_info(df):\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.estimated_size() / (1024**2):.2f} MB\")\n",
    "    print(\"\\nColumn info:\")\n",
    "    for name, dtype in df.schema.items():\n",
    "        print(f\"  {name}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba7fef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (200000000, 2)\n",
      "Memory usage: 3051.76 MB\n",
      "\n",
      "Column info:\n",
      "  id: Int64\n",
      "  value: Float64\n",
      "Shape: (20000, 2)\n",
      "Memory usage: 1.63 MB\n",
      "\n",
      "Column info:\n",
      "  id: Int64\n",
      "  region: String\n"
     ]
    }
   ],
   "source": [
    "polars_info(df_sales_nw)\n",
    "polars_info(df_regions_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4a728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "939276b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After join, columns: ['id', 'value', 'region']\n",
      "Sample row (native): {'id': 1785, 'value': 54.31, 'region': 'North'}\n",
      "Post-filter shape (native): (195448682, 4)\n",
      "Summary by region (pandas):\n",
      "   region   total_value   avg_value  transaction_count\n",
      "0  North  5.038577e+09  102.766448           49029396\n",
      "1   West  5.101366e+09  102.751330           49647685\n",
      "2   East  4.878919e+09  102.760417           47478583\n",
      "3  South  5.065127e+09  102.755460           49293018\n",
      "Execution time: 45.1371 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# 1. Join sales with region labels on 'id'\n",
    "df_joined = df_sales_nw.join(df_regions_nw, on=\"id\", how=\"inner\")\n",
    "print(\"After join, columns:\", df_joined.columns)\n",
    "print(\"Sample row (native):\", nw.to_native(df_joined).iloc[0].to_dict())\n",
    "# 2. Add a derived column: value normalized by overall mean\n",
    "overall_mean = pdf_sales[\"value\"].mean()  # compute using pandas for reference\n",
    "df_joined = df_joined.with_columns(\n",
    "    (nw.col(\"value\") / overall_mean).alias(\"value_norm\")\n",
    ")\n",
    "# 3. Filter rows: keep only transactions with positive value\n",
    "df_joined = df_joined.filter(nw.col(\"value\") > 0)\n",
    "print(\"Post-filter shape (native):\", nw.to_native(df_joined).shape)\n",
    "# 4. Group by region and aggregate total and average value\n",
    "df_summary = df_joined.group_by(\"region\").agg(\n",
    "    nw.col(\"value\").sum().alias(\"total_value\"),\n",
    "    nw.col(\"value\").mean().alias(\"avg_value\"),\n",
    "    nw.len().alias(\"transaction_count\")\n",
    ")\n",
    "# Convert result to native pandas for display\n",
    "summary_native = nw.to_native(df_summary)\n",
    "print(\"Summary by region (pandas):\\n\", summary_native)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5790ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'narwhals.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_sales_nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f761364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  region           sum        mean     count\n",
      "0   East  4.878919e+09  102.760417  47478583\n",
      "1  North  5.038577e+09  102.766448  49029396\n",
      "2  South  5.065127e+09  102.755460  49293018\n",
      "3   West  5.101366e+09  102.751330  49647685\n",
      "Execution time: 41.7422 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Verification using direct pandas (should match summary_native)\n",
    "check = pdf_sales.merge(pdf_regions, on=\"id\").query(\"value > 0\").groupby(\"region\")[\"value\"].agg(['sum','mean','count'])\n",
    "print(check.reset_index())\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9534d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fff8e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by region (Polars):\n",
      " shape: (4, 4)\n",
      "┌────────┬─────────────┬────────────┬───────────────────┐\n",
      "│ region ┆ total_value ┆ avg_value  ┆ transaction_count │\n",
      "│ ---    ┆ ---         ┆ ---        ┆ ---               │\n",
      "│ str    ┆ f64         ┆ f64        ┆ u32               │\n",
      "╞════════╪═════════════╪════════════╪═══════════════════╡\n",
      "│ North  ┆ 5.0386e9    ┆ 102.766448 ┆ 49029396          │\n",
      "│ West   ┆ 5.1014e9    ┆ 102.75133  ┆ 49647685          │\n",
      "│ South  ┆ 5.0651e9    ┆ 102.75546  ┆ 49293018          │\n",
      "│ East   ┆ 4.8789e9    ┆ 102.760417 ┆ 47478583          │\n",
      "└────────┴─────────────┴────────────┴───────────────────┘\n",
      "Execution time: 15.3295 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Using Polars directly (no Narwhals) for comparison:\n",
    "pl_summary = (pl_sales.join(pl_regions, on=\"id\", how=\"inner\")\n",
    "                        .filter(pl.col(\"value\") > 0)\n",
    "                        .with_columns((pl.col(\"value\") / pl.col(\"value\").mean()).alias(\"value_norm\"))\n",
    "                        .group_by(\"region\")\n",
    "                        .agg([\n",
    "                            pl.col(\"value\").sum().alias(\"total_value\"),\n",
    "                            pl.col(\"value\").mean().alias(\"avg_value\"),\n",
    "                            pl.col(\"value\").len().alias(\"transaction_count\")\n",
    "                        ])\n",
    "             )\n",
    "print(\"Summary by region (Polars):\\n\", pl_summary)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0817649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pl_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166bbb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by region (via Narwhals on Polars):\n",
      " shape: (4, 4)\n",
      "┌────────┬─────────────┬────────────┬───────────────────┐\n",
      "│ region ┆ total_value ┆ avg_value  ┆ transaction_count │\n",
      "│ ---    ┆ ---         ┆ ---        ┆ ---               │\n",
      "│ str    ┆ f64         ┆ f64        ┆ u32               │\n",
      "╞════════╪═════════════╪════════════╪═══════════════════╡\n",
      "│ South  ┆ 5.0651e9    ┆ 102.75546  ┆ 49293018          │\n",
      "│ North  ┆ 5.0386e9    ┆ 102.766448 ┆ 49029396          │\n",
      "│ East   ┆ 4.8789e9    ┆ 102.760417 ┆ 47478583          │\n",
      "│ West   ┆ 5.1014e9    ┆ 102.75133  ┆ 49647685          │\n",
      "└────────┴─────────────┴────────────┴───────────────────┘\n",
      "Execution time: 20.2728 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Wrap Polars dataframes with Narwhals and reuse the same transformation pipeline\n",
    "df_sales_nw_pl = nw.from_native(pl_sales)\n",
    "df_regions_nw_pl = nw.from_native(pl_regions)\n",
    "df_summary_pl = (df_sales_nw_pl.join(df_regions_nw_pl, on=\"id\", how=\"inner\")\n",
    "                                .filter(nw.col(\"value\") > 0)\n",
    "                                .with_columns((nw.col(\"value\") / pl_sales[\"value\"].mean()).alias(\"value_norm\")) \n",
    "                                .group_by(\"region\")\n",
    "                                .agg(\n",
    "                                    nw.col(\"value\").sum().alias(\"total_value\"),\n",
    "                                    nw.col(\"value\").mean().alias(\"avg_value\"),\n",
    "                                    nw.len().alias(\"transaction_count\")\n",
    "                                ))\n",
    "summary_pl_native = nw.to_native(df_summary_pl)  # this will be a Polars DataFrame\n",
    "print(\"Summary by region (via Narwhals on Polars):\\n\", summary_pl_native)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e7b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'narwhals.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_summary_pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1c025d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Loading Benchmark (Notebook/VS Code friendly)\n",
    "# pandas vs polars vs narwhals(pandas) vs narwhals(polars)\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import time, statistics as stats, json\n",
    "from typing import Callable, List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import narwhals as nw\n",
    "\n",
    "# ---------- timing helpers ----------\n",
    "def _time_once(fn: Callable[[], object]) -> float:\n",
    "    t0 = time.perf_counter(); _ = fn(); return time.perf_counter() - t0\n",
    "\n",
    "def time_fn(fn: Callable[[], object], repeats: int = 5, warmup: int = 1) -> float:\n",
    "    for _ in range(max(0, warmup)): _ = _time_once(fn)      # warm-up (I/O cache, imports)\n",
    "    return stats.median([_time_once(fn) for _ in range(max(1, repeats))])\n",
    "\n",
    "# ---------- loaders (mirror your four cases) ----------\n",
    "def pandas_loader(p: str):             return pd.read_csv(p)\n",
    "def polars_loader(p: str):             return pl.read_csv(p)\n",
    "def narwhals_pandas_loader(p: str):    return nw.from_native(pd.read_csv(p))\n",
    "def narwhals_polars_loader(p: str):    return nw.from_native(pl.read_csv(p))\n",
    "\n",
    "LOADERS: List[tuple[str, Callable[[str], object]]] = [\n",
    "    (\"Pandas Loading Time\", pandas_loader),\n",
    "    (\"Polars Loading Time\", polars_loader),\n",
    "    (\"Narwhals with Pandas Loading Time\", narwhals_pandas_loader),\n",
    "    (\"Narwhals with Polars Loading Time\", narwhals_polars_loader),\n",
    "]\n",
    "\n",
    "# ---------- benchmarking core ----------\n",
    "def benchmark_csv_loading(\n",
    "    files: list[str | Path] | None = None,\n",
    "    *,\n",
    "    repeats: int = 5,\n",
    "    warmup: int = 1,\n",
    "    save_csv: str | None = \"loading_benchmark.csv\",\n",
    "    save_json: str | None = \"loading_benchmark.json\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with columns:\n",
    "    File | Pandas Loading Time | Polars Loading Time | Narwhals with Pandas Loading Time | Narwhals with Polars Loading Time\n",
    "\n",
    "    - If `files` is None, looks for defaults next to the notebook:\n",
    "      cards_data.csv, transactions_data.csv, users_data.csv.\n",
    "      If none found, falls back to all *.csv in the current directory.\n",
    "    - Filters strictly to .csv files (prevents kernel JSON from being picked).\n",
    "    \"\"\"\n",
    "    cwd = Path.cwd()\n",
    "\n",
    "    if files:\n",
    "        candidates = [Path(f).expanduser().resolve() for f in files]\n",
    "    else:\n",
    "        # Defaults first\n",
    "        defaults = [cwd / \"cards_data.csv\", cwd / \"transactions_data.csv\", cwd / \"users_data.csv\"]\n",
    "        candidates = [p for p in defaults if p.exists()]\n",
    "        # Fallback to all CSVs in CWD if defaults missing\n",
    "        if not candidates:\n",
    "            candidates = sorted(p for p in cwd.glob(\"*.csv\") if p.is_file())\n",
    "\n",
    "    # Keep only existing CSVs\n",
    "    files_resolved = [p for p in candidates if p.suffix.lower() == \".csv\" and p.exists()]\n",
    "    if not files_resolved:\n",
    "        raise FileNotFoundError(\n",
    "            \"No CSV files found. Pass explicit paths, or place CSVs in the notebook folder.\"\n",
    "        )\n",
    "\n",
    "    rows: List[Dict[str, object]] = []\n",
    "    for path in files_resolved:\n",
    "        row: Dict[str, object] = {\"File\": path.name}\n",
    "        for col_name, loader in LOADERS:\n",
    "            try:\n",
    "                elapsed = time_fn(lambda p=str(path): loader(p), repeats=repeats, warmup=warmup)\n",
    "                row[col_name] = round(elapsed, 6)\n",
    "            except Exception as e:\n",
    "                row[col_name] = None\n",
    "                print(f\"[ERROR] {col_name} failed for {path}: {e}\")\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"File\",\n",
    "        \"Pandas Loading Time\",\n",
    "        \"Polars Loading Time\",\n",
    "        \"Narwhals with Pandas Loading Time\",\n",
    "        \"Narwhals with Polars Loading Time\",\n",
    "    ])\n",
    "\n",
    "    # Persist (optional)\n",
    "    if save_csv:\n",
    "        df.to_csv(save_csv, index=False)\n",
    "    if save_json:\n",
    "        with open(save_json, \"w\") as f:\n",
    "            json.dump(rows, f, indent=2)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd01f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CWD = os.getcwd()\n",
    "card_file = os.path.join(CWD, \"cards_data.csv\")\n",
    "transactions_file = os.path.join(CWD, \"transactions_data.csv\")\n",
    "users_file = os.path.join(CWD, \"users_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c73444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Pandas Loading Time</th>\n",
       "      <th>Polars Loading Time</th>\n",
       "      <th>Narwhals with Pandas Loading Time</th>\n",
       "      <th>Narwhals with Polars Loading Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cards_data.csv</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transactions_data.csv</td>\n",
       "      <td>12.692821</td>\n",
       "      <td>0.754228</td>\n",
       "      <td>12.086319</td>\n",
       "      <td>0.855322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>users_data.csv</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.001281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    File  Pandas Loading Time  Polars Loading Time  \\\n",
       "0         cards_data.csv             0.012569             0.002986   \n",
       "1  transactions_data.csv            12.692821             0.754228   \n",
       "2         users_data.csv             0.004642             0.002479   \n",
       "\n",
       "   Narwhals with Pandas Loading Time  Narwhals with Polars Loading Time  \n",
       "0                           0.013106                           0.002632  \n",
       "1                          12.086319                           0.855322  \n",
       "2                           0.004708                           0.001281  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_csv_loading(\n",
    "        files=[\n",
    "                card_file,\n",
    "                transactions_file,\n",
    "                users_file,\n",
    "    ],\n",
    "        repeats=5, warmup=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5e707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PANDAS VS NARWHALS: VERIFICATION OF ALL IDIOMS\n",
      "============================================================\n",
      "\n",
      "1. WRAP/UNWRAP AT I/O EDGE\n",
      "Wrapped pandas type: <class 'narwhals.dataframe.DataFrame'>\n",
      "Wrapped polars type: <class 'narwhals.dataframe.DataFrame'>\n",
      "Unwrapped pandas type: <class 'pandas.core.frame.DataFrame'>\n",
      "Unwrapped polars type: <class 'polars.dataframe.frame.DataFrame'>\n",
      "\n",
      "2. SELECT COLUMNS\n",
      "Pandas: ['a', 'b']\n",
      "Narwhals: ['a', 'b']\n",
      "Narwhals (col): ['a', 'b']\n",
      "\n",
      "3. ADD/REPLACE COLUMN\n",
      "Pandas new column 'z': [3, 2, 9, 4, 15]\n",
      "Narwhals new column 'z': [3, 2, 9, 4, 15]\n",
      "\n",
      "4. RENAME COLUMNS\n",
      "Pandas renamed: ['alpha', 'beta']\n",
      "Narwhals renamed: ['alpha', 'beta']\n",
      "\n",
      "5. DROP COLUMNS\n",
      "Pandas remaining: ['a', 'b', 'x', 'y', 'v', 'd', 'lst']\n",
      "Narwhals remaining: ['a', 'b', 'x', 'y', 'v', 'd', 'lst']\n",
      "\n",
      "6. FILTER ROWS\n",
      "Pandas filtered x values: [1, 3, 5]\n",
      "Narwhals filtered x values: [1, 3, 5]\n",
      "\n",
      "7. SORT\n",
      "Pandas sorted (g,a): [('A', 5), ('A', 3), ('A', 1), ('B', 4), ('B', 2)]\n",
      "Narwhals sorted (g,a): [('A', 5), ('A', 3), ('A', 1), ('B', 4), ('B', 2)]\n",
      "\n",
      "8. HEAD/TAIL\n",
      "Pandas head(2) 'a': [1, 2]\n",
      "Pandas tail(2) 'a': [4, 5]\n",
      "Narwhals head(2) 'a': [1, 2]\n",
      "Narwhals tail(2) 'a': [4, 5]\n",
      "\n",
      "9. SAMPLE ROWS\n",
      "Pandas sample size: 3\n",
      "Narwhals sample size: 3\n",
      "\n",
      "10. DISTINCT/DROP DUPLICATES\n",
      "Pandas unique 'g' values: ['A', 'B']\n",
      "Narwhals unique 'g' values: ['A', 'B']\n",
      "\n",
      "11. UNIQUE VALUES (Series)\n",
      "Pandas unique 's': ['bar', 'baz', 'foo', 'foobar']\n",
      "Narwhals unique 's': ['bar', 'baz', 'foo', 'foobar']\n",
      "\n",
      "12. COALESCE/FIRST NON-NULL\n",
      "Pandas coalesce: [10.0, 2.0, 30.0, 4.0]\n",
      "Narwhals coalesce: [10.0, 2.0, 30.0, 4.0]\n",
      "\n",
      "13. FILL MISSING\n",
      "Pandas filled: [[1.0, -1.0], [0.0, 20.0], [3.0, 30.0]]\n",
      "Narwhals filled: [[1.0, -1.0], [0.0, 20.0], [3.0, 30.0]]\n",
      "\n",
      "14. DROP MISSING\n",
      "Pandas after dropping nulls in 'a': 3\n",
      "Narwhals after dropping nulls in 'a': 3\n",
      "\n",
      "15. TYPE CAST\n",
      "Pandas dtype: float64\n",
      "Narwhals dtype: float64\n",
      "\n",
      "16. STRING CONTAINS\n",
      "Pandas strings with 'foo': ['foo', 'foobar', 'foo']\n",
      "Narwhals strings with 'foo': ['foo', 'foobar', 'foo']\n",
      "\n",
      "17. STRING STARTS/ENDS\n",
      "Pandas starts with 'f': ['foo', 'foobar', 'foo']\n",
      "Narwhals starts with 'f': ['foo', 'foobar', 'foo']\n",
      "\n",
      "18. STRING LOWER/UPPER\n",
      "Pandas lower: ['hello', 'world', 'mixed']\n",
      "Narwhals lower: ['hello', 'world', 'mixed']\n",
      "\n",
      "19. CONDITIONAL COLUMN\n",
      "Pandas conditional: ['Positive', 'Negative', 'Positive', 'Negative', 'Positive']\n",
      "Narwhals conditional: ['Positive', 'Negative', 'Positive', 'Negative', 'Positive']\n",
      "\n",
      "20. GROUP & AGGREGATE\n",
      "Pandas grouped: [['A', 90, 30.0], ['B', 60, 30.0]]\n",
      "Narwhals grouped: [['A', 90, 30.0], ['B', 60, 30.0]]\n",
      "\n",
      "21. GROUP ROW COUNT\n",
      "Pandas group sizes: [['A', 3], ['B', 2]]\n",
      "Narwhals group sizes: [['A', 3], ['B', 2]]\n",
      "\n",
      "22. WINDOW FUNCTIONS\n",
      "Pandas window sum: [('A', 10, 90), ('B', 20, 60), ('A', 30, 90), ('B', 40, 60), ('A', 50, 90)]\n",
      "Narwhals window sum: [('A', 10, 90), ('B', 20, 60), ('A', 30, 90), ('B', 40, 60), ('A', 50, 90)]\n",
      "\n",
      "23. EXPLODE LIST COLUMN\n",
      "Pandas exploded: [1, 2, 3, 4, 5]\n",
      "Narwhals exploded (Polars backend): [1, 2, 3, 4, 5]\n",
      "\n",
      "24. JOIN OPERATIONS\n",
      "Pandas inner join: [[2, 'b', 'x'], [3, 'c', 'y']]\n",
      "Narwhals inner join: [[2, 'b', 'x'], [3, 'c', 'y']]\n",
      "\n",
      "============================================================\n",
      "ALL TESTS COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pandas vs Narwhals: Comprehensive Examples and Verification\n",
    "Testing each idiom from the comparison table\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import narwhals as nw\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Create sample data for testing\n",
    "def create_sample_data():\n",
    "    \"\"\"Create sample DataFrames in both pandas and polars for testing\"\"\"\n",
    "    data = {\n",
    "        'a': [1, 2, 3, 4, 5],\n",
    "        'b': [10, 20, 30, 40, 50],\n",
    "        'x': [1, -2, 3, -4, 5],\n",
    "        'y': [2, 4, 6, 8, 10],\n",
    "        's': ['foo', 'bar', 'foobar', 'baz', 'foo'],\n",
    "        'g': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'v': [100, 200, None, 400, 500],\n",
    "        'd': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],\n",
    "        'lst': [[1, 2], [3], [4, 5, 6], [], [7, 8]]\n",
    "    }\n",
    "    \n",
    "    pdf = pd.DataFrame(data)\n",
    "    pdf['v'] = pdf['v'].astype('float64')  # Handle None as NaN\n",
    "    plf = pl.DataFrame(data)\n",
    "    \n",
    "    return pdf, plf\n",
    "\n",
    "# 1. WRAP/UNWRAP AT I/O EDGE\n",
    "def test_wrap_unwrap():\n",
    "    print(\"1. WRAP/UNWRAP AT I/O EDGE\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Wrap pandas\n",
    "    df_pandas = nw.from_native(pdf)\n",
    "    print(f\"Wrapped pandas type: {type(df_pandas)}\")\n",
    "    \n",
    "    # Wrap polars\n",
    "    df_polars = nw.from_native(plf)\n",
    "    print(f\"Wrapped polars type: {type(df_polars)}\")\n",
    "    \n",
    "    # Unwrap back to native\n",
    "    pdf_back = nw.to_native(df_pandas)\n",
    "    plf_back = nw.to_native(df_polars)\n",
    "    print(f\"Unwrapped pandas type: {type(pdf_back)}\")\n",
    "    print(f\"Unwrapped polars type: {type(plf_back)}\")\n",
    "    print()\n",
    "\n",
    "# 2. SELECT COLUMNS\n",
    "def test_select_columns():\n",
    "    print(\"2. SELECT COLUMNS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_selected = pdf[['a', 'b']]\n",
    "    print(\"Pandas:\", pdf_selected.columns.tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_selected = df.select('a', 'b')\n",
    "    result = nw.to_native(df_selected)\n",
    "    print(\"Narwhals:\", result.columns.tolist())\n",
    "    \n",
    "    # Alternative with nw.col\n",
    "    df_selected2 = df.select([nw.col('a'), nw.col('b')])\n",
    "    result2 = nw.to_native(df_selected2)\n",
    "    print(\"Narwhals (col):\", result2.columns.tolist())\n",
    "    print()\n",
    "\n",
    "# 3. ADD/REPLACE COLUMN\n",
    "def test_add_column():\n",
    "    print(\"3. ADD/REPLACE COLUMN\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_new = pdf.assign(z=pdf.x + pdf.y)\n",
    "    print(\"Pandas new column 'z':\", pdf_new['z'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_new = df.with_columns((nw.col('x') + nw.col('y')).alias('z'))\n",
    "    result = nw.to_native(df_new)\n",
    "    print(\"Narwhals new column 'z':\", result['z'].tolist())\n",
    "    print()\n",
    "\n",
    "# 4. RENAME COLUMNS\n",
    "def test_rename_columns():\n",
    "    print(\"4. RENAME COLUMNS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_renamed = pdf.rename(columns={'a': 'alpha', 'b': 'beta'})\n",
    "    print(\"Pandas renamed:\", pdf_renamed.columns.tolist()[:2])\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_renamed = df.rename({'a': 'alpha', 'b': 'beta'})\n",
    "    result = nw.to_native(df_renamed)\n",
    "    print(\"Narwhals renamed:\", result.columns.tolist()[:2])\n",
    "    print()\n",
    "\n",
    "# 5. DROP COLUMNS\n",
    "def test_drop_columns():\n",
    "    print(\"5. DROP COLUMNS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_dropped = pdf.drop(columns=['s', 'g'])\n",
    "    print(\"Pandas remaining:\", pdf_dropped.columns.tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_dropped = df.drop(['s', 'g'])\n",
    "    result = nw.to_native(df_dropped)\n",
    "    print(\"Narwhals remaining:\", result.columns.tolist())\n",
    "    print()\n",
    "\n",
    "# 6. FILTER ROWS\n",
    "def test_filter_rows():\n",
    "    print(\"6. FILTER ROWS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_filtered = pdf[pdf.x > 0]\n",
    "    print(\"Pandas filtered x values:\", pdf_filtered['x'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_filtered = df.filter(nw.col('x') > 0)\n",
    "    result = nw.to_native(df_filtered)\n",
    "    print(\"Narwhals filtered x values:\", result['x'].tolist())\n",
    "    print()\n",
    "\n",
    "# 7. SORT\n",
    "def test_sort():\n",
    "    print(\"7. SORT\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_sorted = pdf.sort_values(['g', 'a'], ascending=[True, False])\n",
    "    print(\"Pandas sorted (g,a):\", list(zip(pdf_sorted['g'], pdf_sorted['a'])))\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_sorted = df.sort(['g', 'a'], descending=[False, True])\n",
    "    result = nw.to_native(df_sorted)\n",
    "    print(\"Narwhals sorted (g,a):\", list(zip(result['g'], result['a'])))\n",
    "    print()\n",
    "\n",
    "# 8. HEAD/TAIL\n",
    "def test_head_tail():\n",
    "    print(\"8. HEAD/TAIL\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    print(\"Pandas head(2) 'a':\", pdf.head(2)['a'].tolist())\n",
    "    print(\"Pandas tail(2) 'a':\", pdf.tail(2)['a'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    head_result = nw.to_native(df.head(2))\n",
    "    tail_result = nw.to_native(df.tail(2))\n",
    "    print(\"Narwhals head(2) 'a':\", head_result['a'].tolist())\n",
    "    print(\"Narwhals tail(2) 'a':\", tail_result['a'].tolist())\n",
    "    print()\n",
    "\n",
    "# 9. SAMPLE ROWS\n",
    "def test_sample():\n",
    "    print(\"9. SAMPLE ROWS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_sample = pdf.sample(n=3, random_state=42)\n",
    "    print(\"Pandas sample size:\", len(pdf_sample))\n",
    "    \n",
    "    # Narwhals way (note: seed instead of random_state)\n",
    "    df = nw.from_native(pdf)\n",
    "    df_sample = df.sample(n=3, seed=42)\n",
    "    result = nw.to_native(df_sample)\n",
    "    print(\"Narwhals sample size:\", len(result))\n",
    "    print()\n",
    "\n",
    "# 10. DISTINCT/DROP DUPLICATES\n",
    "def test_distinct():\n",
    "    print(\"10. DISTINCT/DROP DUPLICATES\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_unique = pdf.drop_duplicates(subset=['g'])\n",
    "    print(\"Pandas unique 'g' values:\", pdf_unique['g'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_unique = df.unique(subset=['g'])\n",
    "    result = nw.to_native(df_unique)\n",
    "    print(\"Narwhals unique 'g' values:\", result['g'].tolist())\n",
    "    print()\n",
    "\n",
    "# 11. UNIQUE VALUES (Series)\n",
    "def test_unique_values():\n",
    "    print(\"11. UNIQUE VALUES (Series)\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    unique_s = pdf['s'].unique()\n",
    "    print(\"Pandas unique 's':\", sorted(unique_s))\n",
    "    \n",
    "    # Narwhals way (returns 1-col frame)\n",
    "    df = nw.from_native(pdf)\n",
    "    df_unique = df.select(nw.col('s').unique().alias('s'))\n",
    "    result = nw.to_native(df_unique)\n",
    "    print(\"Narwhals unique 's':\", sorted(result['s'].tolist()))\n",
    "    print()\n",
    "\n",
    "# 12. COALESCE/FIRST NON-NULL\n",
    "def test_coalesce():\n",
    "    print(\"12. COALESCE/FIRST NON-NULL\")\n",
    "    pdf = pd.DataFrame({\n",
    "        'a': [None, 2, None, 4],\n",
    "        'b': [10, None, 30, None],\n",
    "        'c': [100, 200, 300, 400]\n",
    "    })\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf['z'] = pdf['a'].fillna(pdf['b']).fillna(pdf['c'])\n",
    "    print(\"Pandas coalesce:\", pdf['z'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_new = df.with_columns(\n",
    "        nw.coalesce([nw.col('a'), nw.col('b'), nw.col('c')]).alias('z')\n",
    "    )\n",
    "    result = nw.to_native(df_new)\n",
    "    print(\"Narwhals coalesce:\", result['z'].tolist())\n",
    "    print()\n",
    "\n",
    "# 13. FILL MISSING\n",
    "def test_fill_missing():\n",
    "    print(\"13. FILL MISSING\")\n",
    "    pdf = pd.DataFrame({'a': [1, None, 3], 'b': [None, 20, 30]})\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_filled = pdf.fillna({'a': 0, 'b': -1})\n",
    "    print(\"Pandas filled:\", pdf_filled.values.tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_filled = df.with_columns(\n",
    "        nw.col('a').fill_null(0).alias('a'),\n",
    "        nw.col('b').fill_null(-1).alias('b')\n",
    "    )\n",
    "    result = nw.to_native(df_filled)\n",
    "    print(\"Narwhals filled:\", result.values.tolist())\n",
    "    print()\n",
    "\n",
    "# 14. DROP MISSING\n",
    "def test_drop_missing():\n",
    "    print(\"14. DROP MISSING\")\n",
    "    pdf = pd.DataFrame({'a': [1, None, 3, 4], 'b': [10, 20, None, 40]})\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_dropped = pdf.dropna(subset=['a'])\n",
    "    print(\"Pandas after dropping nulls in 'a':\", len(pdf_dropped))\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_dropped = df.drop_nulls(['a'])\n",
    "    result = nw.to_native(df_dropped)\n",
    "    print(\"Narwhals after dropping nulls in 'a':\", len(result))\n",
    "    print()\n",
    "\n",
    "# 15. TYPE CAST\n",
    "def test_type_cast():\n",
    "    print(\"15. TYPE CAST\")\n",
    "    pdf = pd.DataFrame({'a': [1, 2, 3]})\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_cast = pdf.astype({'a': 'float64'})\n",
    "    print(\"Pandas dtype:\", pdf_cast['a'].dtype)\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_cast = df.with_columns(nw.col('a').cast(nw.Float64).alias('a'))\n",
    "    result = nw.to_native(df_cast)\n",
    "    print(\"Narwhals dtype:\", result['a'].dtype)\n",
    "    print()\n",
    "\n",
    "# 16. STRING CONTAINS\n",
    "def test_string_contains():\n",
    "    print(\"16. STRING CONTAINS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_filtered = pdf[pdf.s.str.contains('foo', regex=False)]\n",
    "    print(\"Pandas strings with 'foo':\", pdf_filtered['s'].tolist())\n",
    "    \n",
    "    # Narwhals way (literal=True ≈ regex=False)\n",
    "    df = nw.from_native(pdf)\n",
    "    df_filtered = df.filter(nw.col('s').str.contains('foo', literal=True))\n",
    "    result = nw.to_native(df_filtered)\n",
    "    print(\"Narwhals strings with 'foo':\", result['s'].tolist())\n",
    "    print()\n",
    "\n",
    "# 17. STRING STARTS/ENDS\n",
    "def test_string_starts_ends():\n",
    "    print(\"17. STRING STARTS/ENDS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_starts = pdf[pdf.s.str.startswith('f')]\n",
    "    print(\"Pandas starts with 'f':\", pdf_starts['s'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_starts = df.filter(nw.col('s').str.starts_with('f'))\n",
    "    result = nw.to_native(df_starts)\n",
    "    print(\"Narwhals starts with 'f':\", result['s'].tolist())\n",
    "    print()\n",
    "\n",
    "# 18. STRING LOWER/UPPER\n",
    "def test_string_case():\n",
    "    print(\"18. STRING LOWER/UPPER\")\n",
    "    pdf = pd.DataFrame({'s': ['Hello', 'WORLD', 'MiXeD']})\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_lower = pdf.copy()\n",
    "    pdf_lower['s'] = pdf_lower['s'].str.lower()\n",
    "    print(\"Pandas lower:\", pdf_lower['s'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_lower = df.with_columns(nw.col('s').str.to_lowercase().alias('s'))\n",
    "    result = nw.to_native(df_lower)\n",
    "    print(\"Narwhals lower:\", result['s'].tolist())\n",
    "    print()\n",
    "\n",
    "# 19. CONDITIONAL COLUMN\n",
    "def test_conditional():\n",
    "    print(\"19. CONDITIONAL COLUMN\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf['z'] = np.where(pdf.x > 0, 'Positive', 'Negative')\n",
    "    print(\"Pandas conditional:\", pdf['z'].tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_new = df.with_columns(\n",
    "        nw.when(nw.col('x') > 0).then(nw.lit('Positive')).otherwise(nw.lit('Negative')).alias('z')\n",
    "    )\n",
    "    result = nw.to_native(df_new)\n",
    "    print(\"Narwhals conditional:\", result['z'].tolist())\n",
    "    print()\n",
    "\n",
    "# 20. GROUP & AGGREGATE\n",
    "def test_group_aggregate():\n",
    "    print(\"20. GROUP & AGGREGATE\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_agg = pdf.groupby('g')['b'].agg(['sum', 'mean']).reset_index()\n",
    "    print(\"Pandas grouped:\", pdf_agg.values.tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_agg = df.group_by('g').agg(\n",
    "        nw.col('b').sum().alias('sum'),\n",
    "        nw.col('b').mean().alias('mean')\n",
    "    )\n",
    "    result = nw.to_native(df_agg)\n",
    "    print(\"Narwhals grouped:\", result.values.tolist())\n",
    "    print()\n",
    "\n",
    "# 21. GROUP ROW COUNT\n",
    "def test_group_count():\n",
    "    print(\"21. GROUP ROW COUNT\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf_count = pdf.groupby('g').size().reset_index(name='size')\n",
    "    print(\"Pandas group sizes:\", pdf_count.values.tolist())\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_count = df.group_by('g').agg(nw.len().alias('size'))\n",
    "    result = nw.to_native(df_count)\n",
    "    print(\"Narwhals group sizes:\", result.values.tolist())\n",
    "    print()\n",
    "\n",
    "# 22. WINDOW FUNCTIONS\n",
    "def test_window_functions():\n",
    "    print(\"22. WINDOW FUNCTIONS\")\n",
    "    pdf, plf = create_sample_data()\n",
    "    \n",
    "    # Pandas way\n",
    "    pdf['b_sum'] = pdf.groupby('g')['b'].transform('sum')\n",
    "    print(\"Pandas window sum:\", list(zip(pdf['g'], pdf['b'], pdf['b_sum'])))\n",
    "    \n",
    "    # Narwhals way\n",
    "    df = nw.from_native(pdf)\n",
    "    df_new = df.with_columns(nw.col('b').sum().over('g').alias('b_sum'))\n",
    "    result = nw.to_native(df_new)\n",
    "    print(\"Narwhals window sum:\", list(zip(result['g'], result['b'], result['b_sum'])))\n",
    "    print()\n",
    "\n",
    "# 23. EXPLODE LIST COLUMN\n",
    "def test_explode():\n",
    "    print(\"23. EXPLODE LIST COLUMN\")\n",
    "    # For Polars, we need to create the DataFrame differently\n",
    "    # to ensure the list column is properly typed\n",
    "    \n",
    "    # Create with Polars first (it handles list types better)\n",
    "    plf = pl.DataFrame({'id': [1, 2], 'lst': [[1, 2, 3], [4, 5]]})\n",
    "    \n",
    "    # For pandas comparison\n",
    "    pdf = pd.DataFrame({'id': [1, 2], 'lst': [[1, 2, 3], [4, 5]]})\n",
    "    pdf_exploded = pdf.explode('lst')\n",
    "    print(\"Pandas exploded:\", pdf_exploded['lst'].tolist())\n",
    "    \n",
    "    # Narwhals way - using Polars backend which properly handles lists\n",
    "    df = nw.from_native(plf)\n",
    "    df_exploded = df.explode('lst')\n",
    "    result = nw.to_native(df_exploded)\n",
    "    print(\"Narwhals exploded (Polars backend):\", result['lst'].to_list())\n",
    "    \n",
    "    # Note: For pandas backend with Narwhals, list columns need special handling\n",
    "    # The issue is that pandas doesn't have a native List dtype like Polars\n",
    "    print()\n",
    "\n",
    "# 24. JOIN OPERATIONS\n",
    "def test_joins():\n",
    "    print(\"24. JOIN OPERATIONS\")\n",
    "    pdf1 = pd.DataFrame({'id': [1, 2, 3], 'val1': ['a', 'b', 'c']})\n",
    "    pdf2 = pd.DataFrame({'id': [2, 3, 4], 'val2': ['x', 'y', 'z']})\n",
    "    \n",
    "    # Pandas inner join\n",
    "    pdf_joined = pdf1.merge(pdf2, on='id', how='inner')\n",
    "    print(\"Pandas inner join:\", pdf_joined.values.tolist())\n",
    "    \n",
    "    # Narwhals inner join\n",
    "    df1 = nw.from_native(pdf1)\n",
    "    df2 = nw.from_native(pdf2)\n",
    "    df_joined = df1.join(df2, on='id', how='inner')\n",
    "    result = nw.to_native(df_joined)\n",
    "    print(\"Narwhals inner join:\", result.values.tolist())\n",
    "    print()\n",
    "\n",
    "# Run all tests\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PANDAS VS NARWHALS: VERIFICATION OF ALL IDIOMS\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    test_wrap_unwrap()\n",
    "    test_select_columns()\n",
    "    test_add_column()\n",
    "    test_rename_columns()\n",
    "    test_drop_columns()\n",
    "    test_filter_rows()\n",
    "    test_sort()\n",
    "    test_head_tail()\n",
    "    test_sample()\n",
    "    test_distinct()\n",
    "    test_unique_values()\n",
    "    test_coalesce()\n",
    "    test_fill_missing()\n",
    "    test_drop_missing()\n",
    "    test_type_cast()\n",
    "    test_string_contains()\n",
    "    test_string_starts_ends()\n",
    "    test_string_case()\n",
    "    test_conditional()\n",
    "    test_group_aggregate()\n",
    "    test_group_count()\n",
    "    test_window_functions()\n",
    "    test_explode()\n",
    "    test_joins()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ALL TESTS COMPLETED\")\n",
    "    print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
